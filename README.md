# InfraredTags: Invisible AR Markers and Barcodes

   In this tutorial, we show how InfraredTags can be fabricated and decoded using low-cost, infrared-based 3D printing and imaging tools. While any 2D marker can be embedded as InfraredTags, we demonstrate the process for QR codes and ArUco markers. This research project has been published at the [2022 ACM CHI](https://chi2022.acm.org/) Conference on Human Factors in Computing Systems. Learn more about the project [here](https://hcie.csail.mit.edu/research/infraredtags/infraredtags.html).

<p align="center">
  <img  height="290" src="readme_img/InfraredTags_Teaser.png">
</p>

## #1 CAD: Adding the tag into the object
### Requirements
- Rhino 3D (make sure it is version 6) and [Grasshopper 3D](https://www.rhino3d.com/download/archive/rhino-for-windows/6/latest/)
        - Once installed, follow the instructions to install the [Pufferfish plugin](https://github.com/HCIELab/InfraTags/tree/main/public/encoder/plugins/Pufferfish3-0)
- Python and IDE (Any IDE will work, however, we use [pycharm](https://www.jetbrains.com/pycharm/download/#section=windows))
### Using the encoder
#### 1) Open the Encoder_V1.gh file
<p align="center">
  <img height="150" src="readme_img/file.png">
</p>

#### 2) Import STL file
<p align="center">
  <img  height="200" src="/readme_img/inputs_stl.png">
</p>

#### 3) Import SVG (here is where it gets slightly complicated)
   -  The SVGs have to be in a specific format in order for our Grasshopper code to parse it (see [below](#svg-formating)).

<p align="center">
  <img  height="200" src="/readme_img/inputs_svg.png">
</p>

- Once imported you should see this:

<p align="center">
  <img  height="200" src="/readme_img/output_sm.png">
</p>

#### 4) Change the xyz coordinate of the point to move the code around on the surface of the object
   - Best way to move a point is to simply set the coordinates by right clicking "Pt" on the inputs panel and then going to manage collection and typing a new point
   - Due to a bug in the code, it is best to keep the point in the positive z-axis.


<p align="center">
  <img  height="200" src="https://github.com/HCIELab/InfraTags/blob/main/public/readme_img/input_pt.png">
</p>
<p align="center">
  <img  height="200" src="https://github.com/HCIELab/InfraTags/blob/main/public/readme_img/input_manage_collection.png">
</p>



#### 5) Set top layer thickness and air gap thickness (1.38mm and 1.92mm respectively for White PLA and IR PLA)

#### 6) Export STLs:
   - For single-material, right click "single material" and click "bake". For multi-material, right click on both "multi material" and "IR filament"
   - A black wire mesh should appear in the perspective screen
   - Simply highlight it with your mouse then navigate to File > Export selected and save somewhere in your file system
   - Note: for multi material you need to bake and export each mesh seperatley that way you have both the internal PLA component and the outer IR PLA component. 
<p align="center">
   <img  height="200" src="https://github.com/HCIELab/InfraTags/blob/main/public/readme_img/sm_save.png">
</p>
<p align="center">
   <img  height="200" src="https://github.com/HCIELab/InfraTags/blob/main/public/readme_img/sm_mesh.png">
</p>
<p align="center">
   <img  height="200" src="https://github.com/HCIELab/InfraTags/blob/main/public/readme_img/code_mesh.png">
</p>

#### SVG formating
   - To format the SVG you have two options:
      - Take the original SVG and parse it into paths of the following format: ```<path d="Mx,yhavbh-az"></path>```
         - x,y are the starting position 
         - A is horizontal length, b is vertical length
         - Ex:  ```<path d="M0,0h5v6h-5z"></path>``` 
      - An easier solution is to use webisites that generate the codes automatically and some python :
         - For QR codes use svgs generated by this library (https://www.nayuki.io/page/qr-code-generator-library).
         - For Aruco get svgs from this library (https://chev.me/arucogen/) and then save the svg and keep track of its path then pass it into the "Aruco_to_Path.py" file changing the paths in line 84 and 85. 

## #2 Fabrication: 3D printing the object
#### Materials
   - Although our technique can be used with many filaments we recommend using white PLA and IR PLA ([link to IR pla](https://3dk.berlin/en/special/115-pla-filament-ir-black.html))
  
#### 1) Open the Cura slicer (or any slicer that supports multi-material prints)

#### 2) Import both models (IR PLA and regular PLA)

<p align="center">
   <img  height="200" src="https://github.com/HCIELab/InfraTags/blob/main/public/readme_img/slr_import.png">
</p>

#### 3) Arrange and slice   
    
<p align="center">
   <img  height="200" src="https://github.com/HCIELab/InfraTags/blob/main/public/readme_img/slr_arrange.png">
</p>


<p align="center">
   <img  height="200" src="https://github.com/HCIELab/InfraTags/blob/main/public/readme_img/slr_gcode.png">
</p>

## #3 Detection: Reading the tags
#### Materials
 - Raspberry Pi NoIR Camera [(link)](https://www.amazon.com/kuman-Raspberry-Camera-Module-Supports/dp/B0759GYR51/ref=sr_1_25?crid=IJE0D6SB8AQG&keywords=PI+noir+5MP&qid=1653020486&s=electronics&sprefix=pi+noir+5mp%2Celectronics%2C88&sr=1-25)
 - Raspberry Pi Zero [(link)](https://www.raspberrypi.com/products/raspberry-pi-zero/)
 - Micro-USB to USB type A cable [(link)](https://www.amazon.com/AmazonBasics-Male-Micro-Cable-Black/dp/B07232M876/ref=sr_1_3?keywords=micro+usb+to+usb&qid=1653020580&sr=8-3)
 - (Optional) 3D printed camera case to house all parts [(link)](https://github.com/HCIELab/InfraTags/tree/main/public/hardware/Camera_Case)
#### Hardware 
   - Once a Raspberry Pi and near-infrared camera are obtained. follow the instructions at this [link](https://tutorial.cytron.io/2020/12/29/raspberry-pi-zero-usb-webcam/) and follow the instructions to set up the pi + camera as a usb camera 
#### Software
   - It is recommend that you use pycharm to run the decoder demos both for QR and Aruco, however the code can be run from a terminal 
   - Have Python3 and pip3 pre-installed on your system link for this is [here](https://www.python.org/downloads/) version 3.6 or greater should work just fine
   - Run the following command in terminal:
      - ```pip install opencv-python numpy dbr opencv-contrib-python pyzbar```
   - Or in pycharm navigate to File > Settings > Project > Python Interpreter > Install packages (click the plus sign) and install the following packages:
      - opencv-python 
      - numpy
      - dbr
      - opencv-contrib-python
      - pyzbar
## Using the Decoder
### QR code
   - Navigate to qr_demo > qr_demo.py 
   - Open the file in an editor
   - Navigate to line 22 and confirm that CAMERA_STREAM is 1, indicating the usb camera
   - You should see a window popup in your screen if everything went alright 
   - There should also be a terminal outputting data on whether a code was detected or not
   - [put pictures here dont have pi IR camera to put images]
   
### ArUco
   - Navigate to aruco_demo > aruco_demo.py
   - Open the file in an editor
   - Navigate to line 20 and confirm that CAMERA_STREAM is 1, indicating the usb camera
   - You should see a window popup in your screen if everything went alright
   - There should also be a terminal outputting data on whether a code was detected or not
   - [put pictures here dont have pi IR camera to put images]
  
### Calibratiing the Image Transforms for Aruco Code
You should only do this if you want to change the Parameters for the Aroco detection
   - Navigate to infrared_python_api and open irtags_calib.py 
   - Navigate to line 17 and confirm VIDEO_STREAM is 1 for the usb IR camera
   - A window with a panel should open on the right play around with the values until a code is detected 
   - Take note of these values, these values can be used to change the parameters for the image transforms
  
### OnePlus
   #### Hardware
   - OnePlus 8 Pro (found [here](https://www.oneplus.com/8-pro)) with Android 11. This phone has an embedded near-infrared camera. You can buy a used one from Amazon.

   #### Software
   - ADB shell ([insallation guide](https://www.xda-developers.com/install-adb-windows-macos-linux/))
   - Follow the steps to enable wireless debugging on the OnePlus and pair with your PC ([here](https://medium.com/android-news/wireless-debugging-through-adb-in-android-using-wifi-965f7edd163a))
   
   #### Decoding
   - Once everything is installed, and you have paired the OnePlus to your computer via adb, you can run this command to get the IR camera show up:
   ```adb shell am start -n com.oneplus.factorymode/.camera.manualtest.CameraManualTest``` (more detail [here](https://www.xda-developers.com/oneplus-8-pro-color-filter-camera-still-accessible-adb-command/))
   - You should see the IR stream open on the OnePlus:
    <p align="center"> <img  height="450" src="https://github.com/HCIELab/InfraTags/blob/main/public/readme_img/oneplus_ir.png"> </p>
   - Note: if you do not see the IR camera, you may have to change the camera view to camera view 4 as seen in the top right of the image
   - It is important that once you are in camera view 4/IR camera view do not change views again. The app will freeze and you will need to restart the phone and resend the command to open the IR view again. 
   - Finally, after all this is done navigate to the oneplus folder ([here](https://github.com/HCIELab/InfraTags/tree/main/public/oneplus)) and run onplus.py. This should open up a window on your PC, livestreaming the oneplus' screen
  
### QR code detection
 - All the demo code above for detecting QR codes uses [Dynamsoft Barcode Reader (DBR)](https://www.dynamsoft.com/barcode-reader/overview/) in the backend. Our code comes with a 1-day public trial license which must be renewed after expiration. 
 - If you do not renew the license, you will get only partial decoding of messages.
 - To update the license key navigate to the dbr_decode.py file for each demo and change the license key variable (line 4 of dbr_decode.py).
 
